{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "First, we must ensure that the Watson Python SDK is installed and ready to use, we'll then import the SDK as well as the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm-watson==5.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import DiscoveryV1\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Watson Discovery\n",
    "\n",
    "Now we'll initialize Watson Discovery using our login credentials. In order to obtain these, create a Watson Discovery services with your IBM Cloud account, and generate new credentials.\n",
    "\n",
    "https://cloud.ibm.com/apidocs/discovery?code=python#authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: import the modules from the sdk\n",
    "\n",
    "# TO DO: authenticate via the sdk, let it manage the token lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the query\n",
    "\n",
    "There are a few elements to querying Watson Discovery news, I'll break down each of the elements.\n",
    "\n",
    "`environment_id`: `system` just denotes that we're using the system environment\n",
    "\n",
    "`collection_id`: We want to query the news collection\n",
    "\n",
    "`natural_language_query`: string for free text search\n",
    "\n",
    "`offset`: The number of results (documents) to skip\n",
    "\n",
    "`count`: The number of results (documents) to return \n",
    "\n",
    "***note: Count and offset is the way pagination of results is implemented, the maximum of total results (offset + count) cannot exceed 10,000***\n",
    "\n",
    "`aggregation`: This is a analytic query of the results set\n",
    "\n",
    "`filter`: The query for matching documents\n",
    "\n",
    "`return_`: What items to actually return to us for our use\n",
    "\n",
    "**For more information, check out the [query reference](https://cloud.ibm.com/docs/services/discovery/query-reference.html#query-reference)**\n",
    "\n",
    "\n",
    "We are using DEFAULT_COUNT of 50, the maximum you can query at once, and incrementing until we've captured all available documents or hit 10000 (the maximum).\n",
    "\n",
    "https://cloud.ibm.com/apidocs/discovery?code=python#query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the results from discovery news into the list all_results\n",
    "all_results = []\n",
    "\n",
    "# TO DO: query the service via the sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(all_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Enrichments\n",
    "\n",
    "Now that we've queried Watson Discovery, we want to analyze in detail each article.\n",
    "\n",
    "So we are going to use the `url` info that we obtained for each result to perform a detailed query with **Natural Language Understanding**.\n",
    "\n",
    "Note that this is different in comparison to the `enrich_text.sentiment` field that can be returned by Watson Discovery call, as it \"only\" analyzes what is contained within the `text` field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Watson Natural Language Understanding \n",
    "\n",
    "Now we'll initialize Watson Natural Language Understanding using our login credentials. In order to obtain these, create a Watson Natural Language Understanding services with your IBM Cloud account, and generate new credentials.\n",
    "\n",
    "https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: import the modules from the sdk\n",
    "\n",
    "# TO DO: authenticate via the sdk, let it manage the token lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features you want to extract with NLU.\n",
    "For example, let's activate the **sentiment** analysis and the **keywords** extraction, and pass the url extracted for each result as a query parameter to the service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example test\n",
    "Perform a simple API call to Natural Language Understanding service\n",
    "\n",
    "https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: import the modules for extracting specific features from NLU\n",
    "\n",
    "# TO DO: perform the query \"analyze\" with the sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: for each result in all_results,\n",
    "#        perform a query to NLU and add sentiment and keywords resulting from NLU to the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(all_results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
